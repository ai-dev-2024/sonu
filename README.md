# SONU - Offline Voice Typing Application

<div align="center">

![SONU Logo](assets/tray/mic-32.png)

**Professional-grade offline voice typing solution powered by Faster-Whisper AI**

[![Video Formats](https://img.shields.io/badge/video-MP4%20%7C%20H.265%20%7C%20VP9-orange)](#-showcase)
[![Screenshots](https://img.shields.io/badge/screenshots-17-blue)](#-showcase)
[![Version](https://img.shields.io/badge/version-3.5.4-blue.svg)](https://github.com/ai-dev-2024/sonu)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![Platform](https://img.shields.io/badge/platform-Windows-lightgrey.svg)](https://www.microsoft.com/windows)
[![Python](https://img.shields.io/badge/python-3.8%2B-blue.svg)](https://www.python.org/)
[![Node.js](https://img.shields.io/badge/node.js-16.0%2B-green.svg)](https://nodejs.org/)

*Transform your voice into text instantly, completely offline, with enterprise-grade accuracy*

---

### ğŸ¯ **Development Goal: Professional Development Tools & Sponsorship**

SONU was developed using a suite of AI-augmented development tools including **Cursor Free/Pro (7-day trial)**, **KiloCode**, **VS Code**, **Klein**, and **RooCode**. This project demonstrates the power of collaborative AI-assisted development, and to continue building professional-grade features and maintain rapid development cycles, **the primary goal is to obtain a Cursor Ultra subscription**.

**We welcome any form of sponsorship or support** that helps maintain and enhance the development workflow. Whether it's Cursor Ultra, alternative development tools, or direct contributions, **any help and donation is greatly appreciated**.

**Your support directly enables:**
- âš¡ Faster feature development and bug fixes
- ğŸš€ Enhanced AI-powered code quality
- ğŸ’¼ Professional-grade development tools
- ğŸ¯ Continued innovation and improvements

**[ğŸ‘‰ Support via Ko-fi](https://ko-fi.com/ai_dev_2024)** | Any contribution makes a meaningful difference! ğŸ™

---

</div>

<div align="center">

<!-- Banner GIF/PNG preview -->
![SONU Showcase Banner](assets/showcase/banner.png)

<br/>
<sub>Quickstart showcase generation: <code>npm run showcase</code> Â· Banner: <code>npm run banner</code></sub>

</div>

---

## ğŸ“¸ Showcase

<div align="center">

### Application Overview

<table>
  <tr>
    <td align="center"><strong>Home Dashboard</strong></td>
    <td align="center"><strong>Dictionary Workspace</strong></td>
    <td align="center"><strong>Snippets Library</strong></td>
  </tr>
  <tr>
    <td><img src="https://raw.githubusercontent.com/ai-dev-2024/sonu/desktop-v3/apps/desktop/assets/showcase/01-home.png" alt="Home Dashboard" width="100%"></td>
    <td><img src="https://raw.githubusercontent.com/ai-dev-2024/sonu/desktop-v3/apps/desktop/assets/showcase/02-dictionary.png" alt="Dictionary Workspace" width="100%"></td>
    <td><img src="https://raw.githubusercontent.com/ai-dev-2024/sonu/desktop-v3/apps/desktop/assets/showcase/03-snippets.png" alt="Snippets Library" width="100%"></td>
  </tr>
  <tr>
    <td align="center"><strong>Style Presets</strong></td>
    <td align="center"><strong>Notes Dashboard</strong></td>
    <td align="center"><strong>Settings - General</strong></td>
  </tr>
  <tr>
    <td><img src="https://raw.githubusercontent.com/ai-dev-2024/sonu/desktop-v3/apps/desktop/assets/showcase/04-style.png" alt="Style Presets" width="100%"></td>
    <td><img src="https://raw.githubusercontent.com/ai-dev-2024/sonu/desktop-v3/apps/desktop/assets/showcase/05-notes.png" alt="Notes Dashboard" width="100%"></td>
    <td><img src="https://raw.githubusercontent.com/ai-dev-2024/sonu/desktop-v3/apps/desktop/assets/showcase/06-settings-general.png" alt="Settings - General" width="100%"></td>
  </tr>
  <tr>
    <td align="center"><strong>Settings - System</strong></td>
    <td align="center"><strong>Settings - Model Selector</strong></td>
    <td align="center"><strong>Settings - Themes</strong></td>
  </tr>
  <tr>
    <td><img src="https://raw.githubusercontent.com/ai-dev-2024/sonu/desktop-v3/apps/desktop/assets/showcase/07-settings-system.png" alt="Settings - System" width="100%"></td>
    <td><img src="https://raw.githubusercontent.com/ai-dev-2024/sonu/desktop-v3/apps/desktop/assets/showcase/08-settings-model.png" alt="Settings - Model Selector" width="100%"></td>
    <td><img src="https://raw.githubusercontent.com/ai-dev-2024/sonu/desktop-v3/apps/desktop/assets/showcase/09-settings-themes.png" alt="Settings - Themes" width="100%"></td>
  </tr>
  <tr>
    <td colspan="3" align="center"><strong>Dark Theme</strong></td>
  </tr>
  <tr>
    <td colspan="3"><img src="https://raw.githubusercontent.com/ai-dev-2024/sonu/desktop-v3/apps/desktop/assets/showcase/10-home-dark.png" alt="Home in Dark Theme" width="100%"></td>
  </tr>
</table>

### Video Showcase

<table>
  <tr>
    <td colspan="3" align="center">
      <h3>ğŸ¬ Video Demonstrations</h3>
      <p>
        <a href="https://github.com/ai-dev-2024/sonu/blob/desktop-v3/apps/desktop/assets/showcase/showcase.mp4">ğŸ“¹ MP4 Montage</a> Â·
        <a href="https://github.com/ai-dev-2024/sonu/blob/desktop-v3/apps/desktop/assets/showcase/showcase_vp9.webm">ğŸ“¹ VP9 Montage</a> Â·
        <a href="https://github.com/ai-dev-2024/sonu/blob/desktop-v3/apps/desktop/assets/showcase/showcase_h265.mp4">ğŸ“¹ HEVC Montage</a>
      </p>
      <p>
        <strong>Slideshows:</strong><br>
        <a href="https://github.com/ai-dev-2024/sonu/blob/desktop-v3/apps/desktop/assets/showcase/showcase_slideshow_h265.mp4">HEVC Slideshow</a> Â·
        <a href="https://github.com/ai-dev-2024/sonu/blob/desktop-v3/apps/desktop/assets/showcase/showcase_slideshow_vp9.webm">VP9 Slideshow</a> Â·
        <a href="https://github.com/ai-dev-2024/sonu/blob/desktop-v3/apps/desktop/assets/showcase/showcase_slideshow_3s_h265.mp4">HEVC (Ken Burns)</a> Â·
        <a href="https://github.com/ai-dev-2024/sonu/blob/desktop-v3/apps/desktop/assets/showcase/showcase_slideshow_3s_vp9.webm">VP9 (Ken Burns)</a>
      </p>
    </td>
  </tr>
</table>

<sub>âœ¨ Screenshots and videos are auto-generated via <code>npm run showcase</code> and saved to <code>apps/desktop/assets/showcase/</code></sub>

</div>
---

## ğŸš€ Overview

**SONU** is a cutting-edge desktop application that provides real-time voice-to-text transcription using OpenAI's Whisper model via the faster-whisper library, running entirely offline on your Windows machine. Built with Electron and Python using Cursor Free/Pro (7-day trial), KiloCode, VS Code, Klein, and RooCode, SONU offers a seamless, privacy-focused dictation experience that works across all your applications.

### Key Highlights

- âœ… **100% Offline** - No internet connection required, complete privacy
- âœ… **Real-time Transcription** - Live partial results during dictation
- âœ… **Dual Interaction Modes** - Press-and-hold or toggle on/off
- âœ… **System-wide Integration** - Works in any application
- âœ… **Professional UI** - Modern, glassmorphic design with light/dark themes
- âœ… **Enterprise Ready** - Commercial-grade architecture and documentation
- âœ… **Faster-Whisper Powered** - CPU-optimized transcription engine

---

## âœ¨ Features

### Core Functionality

- **Press-and-Hold Mode**: Hold a hotkey to dictate, release to finalize and output text
- **Toggle Mode**: Start/stop continuous dictation with a single keypress
- **Instant Hotkey Response**: Zero-latency hotkey triggering - dictation starts immediately
- **Live Preview**: See partial transcriptions in real-time during dictation
- **Instant System-wide Output**: Text appears instantly at cursor location in any application (like Wispr Flow)
  - Uses modern native addon for fastest typing performance
  - Automatic fallback to clipboard method for reliability
  - Works seamlessly across all Windows applications
- **Clipboard Integration**: Final transcriptions automatically copied to clipboard
- **History Management**: View, edit, and copy previous transcriptions (last 100 items)

### Model Management

- **Multiple Model Sizes**: Choose from tiny, base, small, medium, or large-v3 models
- **Auto-Download**: Automatic model download with progress tracking
- **Model Import**: Import locally downloaded models
- **Smart Recommendations**: System-based model recommendations
- **Cache Management**: Automatic detection of faster-whisper cache locations

### User Interface

- **Modern Design**: Glassmorphic UI inspired by Apple's design language
- **Theme Support**: Beautiful light and dim dark themes with smooth transitions
- **Responsive Layout**: Sidebar navigation with dedicated settings page
- **Live Statistics**: Track total transcriptions, words, and characters
- **Inline Editing**: Edit history items directly in the interface

### Advanced Features

- **Customizable Hotkeys**: Configure hold and toggle shortcuts to your preference
- **Instant Typing Technology**: Multi-tier typing system with automatic fallback
  - Primary: Native addon (`@xitanggg/node-insert-text`) for fastest performance
  - Fallback: Clipboard + Ctrl+V method (what Wispr Flow uses)
  - Final: Clipboard-only if automation unavailable
- **Audio Cues**: Audio feedback for dictation start/stop
- **Tray Integration**: System tray icon with comprehensive context menu
- **Window Controls**: Standard minimize, maximize, and close functionality
- **Version Management**: Built-in versioning system for development

---

## ğŸ“‹ Requirements

### System Requirements

- **OS**: Windows 10/11 (64-bit)
- **RAM**: Minimum 4GB (8GB recommended)
- **Storage**: 2GB free space (for models)
- **Audio**: Microphone input device

### Software Dependencies

- **Node.js**: v16.0.0 or higher
- **Python**: 3.8 or higher
- **Python Packages**:
  - `faster-whisper` (Whisper model implementation)
  - `pyaudio` (Audio capture)

---

## ğŸ› ï¸ Installation

### Prerequisites

1. **Install Node.js**
   ```bash
   # Download from https://nodejs.org/
   # Verify installation
   node --version
   npm --version
   ```

2. **Install Python**
   ```bash
   # Download from https://www.python.org/
   # Verify installation
   python --version
   pip --version
   ```

3. **Install Python Dependencies**
   ```bash
   pip install faster-whisper pyaudio
   ```

### Application Setup

1. **Clone the Repository**
   ```bash
   git clone https://github.com/ai-dev-2024/sonu.git
   cd sonu
   ```

2. **Navigate to Desktop App**
   ```bash
   cd apps/desktop
   ```

3. **Install Dependencies**
   ```bash
   npm install
   pip install -r requirements.txt
   ```

4. **Run the Application**
   ```bash
   npm start
   ```

### Building for Distribution

```bash
npm run build
```

This creates a Windows installer in the `dist` folder.

## ğŸ“¸ Automated Showcase Capture

Generate fresh screenshots of every major tab without manual clicking:

```bash
npm run showcase
```

The command launches SONU in a special showcase mode, walks through Home, Dictionary, Snippets, Style, Notes, and all Settings sub-pages, and saves PNGs to `assets/showcase/`. To turn the stills into a short MP4 for GitHub or the redbook, run (requires `ffmpeg`):

```bash
ffmpeg -y -framerate 1 -pattern_type glob -i "assets/showcase/*.png" -c:v libx264 -pix_fmt yuv420p assets/showcase/showcase.mp4
```

### Alternative: Playwright Automation

If you prefer Playwright-driven automation (video + screenshots), use:

```bash
npm run auto-screenshots
```

This runs `auto_screenshot.js`, capturing screenshots to `screenshots/` and a walkthrough video to `recordings/`. See `AUTOMATION_README.md` for details.

### Showcase Videos

- HEVC (H.265) slideshow: `assets/showcase/showcase_slideshow_h265.mp4`
- VP9 (WebM) slideshow: `assets/showcase/showcase_slideshow_vp9.webm`
- Original MP4 montage: `assets/showcase/showcase.mp4`
- Social-ready HEVC: `assets/showcase/showcase_h265.mp4`
- Social-ready VP9: `assets/showcase/showcase_vp9.webm`

--- 

## ğŸ¯ Usage

### First Launch

1. Launch SONU from the command line or desktop shortcut
2. The application will start minimized to the system tray
3. Right-click the tray icon to access the main window

### Basic Dictation

#### Press-and-Hold Mode

1. **Configure Hotkey**: Go to Settings â†’ Keyboard Shortcuts â†’ Hold Key
2. **Default**: `Ctrl+Win+Space` (customizable)
3. **Usage**: 
   - Hold the configured hotkey combination
   - Speak your text
   - Release to finalize and output

#### Toggle Mode

1. **Configure Hotkey**: Go to Settings â†’ Keyboard Shortcuts â†’ Toggle Key
2. **Default**: `Ctrl+Shift+Space` (customizable)
3. **Usage**:
   - Press once to start dictation
   - Speak your text (see live partial transcriptions in real-time)
   - Press again to stop and output text instantly
4. **Features**:
   - **Instant Output**: Text appears immediately when toggled off using the last partial transcription
   - **Live Previews**: Real-time partial transcriptions during recording (same as hold mode)
   - **Reliable**: Stable operation even with rapid toggle sequences

### Model Management

1. **Select Model**: Go to Settings â†’ Model Selector
2. **Download Model**: Click "Download and Apply" for your preferred model
3. **Import Model**: Use "Import Model File" to use a locally downloaded model
4. **Auto-Recommendation**: System will recommend the best model based on your hardware

### Advanced Usage

- **View History**: Access previous transcriptions from the Home page
- **Edit Transcripts**: Click any history item to edit before copying
- **Change Themes**: Toggle between light and dark themes via the header switch
- **Customize Settings**: Access comprehensive settings via the sidebar
- **Dictionary Management**: Add custom words to improve transcription accuracy
- **Waveform Animation**: Control the visual waveform indicator during dictation
  - Go to Settings â†’ Vibe Coding â†’ "Show Live Waveform Animation"
  - When **ON**: The floating widget with animated waveform bars appears during dictation
  - When **OFF**: Dictation works normally but the widget is completely hidden
  - The setting applies immediately - toggle it on/off while dictating to see the change

---

## âš™ï¸ Configuration

### Hotkey Configuration

Hotkeys are configured in the Settings UI (no config.json needed).

### Settings Configuration

Settings are stored in `apps/desktop/data/settings.json`:

```json
{
  "theme": "dark",
  "selected_model": "base",
  "dictation_hotkey": "Ctrl+Space",
  "sound_feedback": true,
  "waveform_animation": true,
  "model_download_path": ""
}
```

### Dictionary Management

Add custom words in the Dictionary tab of the app. Words are stored in `apps/desktop/data/dictionary.json`.

---

## ğŸ—ï¸ Architecture

### Technology Stack

- **Frontend**: Electron (Chromium + Node.js)
- **Backend**: Python 3.x
- **AI Model**: Faster-Whisper (OpenAI Whisper implementation)
- **UI Framework**: Vanilla HTML/CSS/JavaScript
- **System Integration**: robotjs (system-wide typing)

### Project Structure

```
sonu/
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ desktop/          # Desktop app (v3.x) - ACTIVE
â”‚   â”‚   â”œâ”€â”€ main.js       # Electron main process
â”‚   â”‚   â”œâ”€â”€ index.html    # Main UI
â”‚   â”‚   â”œâ”€â”€ renderer.js   # Renderer process
â”‚   â”‚   â”œâ”€â”€ package.json  # Desktop dependencies
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ mobile/           # Mobile app (v4+) - Future
â”œâ”€â”€ versions/             # Historical versions
â”‚   â”œâ”€â”€ v3.legacy/        # Archived root files
â”‚   â””â”€â”€ ...
â”œâ”€â”€ assets/               # Application assets
â”œâ”€â”€ docs/                 # Documentation
â”œâ”€â”€ scripts/              # Utility scripts
â”œâ”€â”€ tests/                # Test configurations
â””â”€â”€ [config files]        # Project-wide configs
```

### Key Components

1. **Main Process** (`main.js`): Window management, hotkey registration, IPC handling, model management
2. **Renderer Process** (`renderer.js`): UI state management, user interactions
3. **Whisper Service** (`whisper_service.py`): Audio capture and transcription using faster-whisper
4. **Preload Script** (`preload.js`): Secure IPC communication bridge
5. **Model Manager** (`model_manager.py`): Model download and cache management

### Faster-Whisper Integration

SONU uses **faster-whisper** (not whisper.cpp) for transcription:

- **Model Names**: Uses faster-whisper standard names (tiny, base, small, medium, large-v3)
- **Cache Location**: 
  - Windows: `%LOCALAPPDATA%\.cache\huggingface\hub\models--openai--whisper-{model}\`
  - Linux/Mac: `~/.cache/huggingface/hub/models--openai--whisper-{model}/`
- **Download**: Automatically downloads from Hugging Face Systran repositories
- **CPU Optimized**: Uses CTranslate2 for efficient CPU-based transcription

---

## ğŸ”’ Privacy & Security

- **100% Offline**: All processing happens locally on your machine
- **No Data Transmission**: Audio never leaves your device
- **No Telemetry**: Zero tracking or analytics
- **Open Source**: Full source code transparency
- **Local Storage**: All data stored locally in JSON files
- **No Cloud Sync**: All data remains on your device

---

## ğŸ› Troubleshooting

### Common Issues

**Issue**: Hotkeys not working
- **Solution**: Ensure no other application is using the same hotkey combination
- **Solution**: Check Windows permissions for global hotkey registration

**Issue**: Audio not being captured
- **Solution**: Verify microphone permissions in Windows Settings
- **Solution**: Check if microphone is set as default input device

**Issue**: Transcription not appearing
- **Solution**: Ensure Python dependencies are installed correctly
- **Solution**: Check console for error messages
- **Solution**: Verify faster-whisper is installed: `pip install faster-whisper`

**Issue**: System-wide typing not working
- **Solution**: Verify `robotjs` is installed: `npm install robotjs`
- **Solution**: Use clipboard fallback (`Ctrl+V`) if robotjs unavailable

**Issue**: Model download fails
- **Solution**: Check internet connection (required only for initial download)
- **Solution**: Verify faster-whisper is installed correctly
- **Solution**: Check disk space availability

### Performance Optimization

- **First Run**: Initial model loading may take 30-60 seconds
- **Memory Usage**: Whisper model requires ~2GB RAM (varies by model size)
- **CPU Usage**: Transcription is CPU-intensive; expect 20-40% usage
- **Model Selection**: Use smaller models (tiny, base) for faster transcription

---

## ğŸ“ Development

### Version History

See [CHANGELOG.md](CHANGELOG.md) for detailed version history.

### Contributing

We welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

1. Fork the repository
2. Create a feature branch from `main`
3. Make your changes
4. Test thoroughly
5. Submit a pull request

### Building from Source

```bash
# Navigate to desktop app
cd apps/desktop

# Install dependencies
npm install
pip install -r requirements.txt

# Run in development mode
npm start

# Build for production
npm run build
```

### Running Tests

#### Automated Testing (Recommended)

Run all tests, generate showcases, and upload to GitHub automatically:

```bash
cd apps/desktop
npm run test:auto
```

This command:
- âœ… Runs unit, integration, and E2E tests
- âœ… Tests all features: Dictionary, Snippets, Notes, Theme, Experimental toggles
- âœ… Generates showcase screenshots
- âœ… Uploads to GitHub automatically

#### Manual Testing

Run tests from the dedicated `tests` workspace:

```bash
cd apps/desktop/tests
npm install

# Unit / Integration / E2E
npm run test:unit
npm run test:integration
npm run test:e2e

# Complete functionality tests (all features)
npm run test:e2e:complete

# Real-time comprehensive tests (clicks all buttons, tests downloads, toggles, copy functions)
npm run test:realtime
```

Alternatively, from the project root using Jest directly:

```bash
npx jest tests/unit --runInBand
npx jest tests/integration --runInBand
npx jest tests/e2e --runInBand
```

#### Test Coverage

The comprehensive test suite covers:
- âœ… Dictionary CRUD operations (add, delete words)
- âœ… Snippets CRUD operations
- âœ… Notes CRUD operations
- âœ… Theme switching and persistence
- âœ… All experimental feature toggles (continuous dictation, low-latency, noise reduction)
- âœ… General settings toggles (sound feedback, waveform animation)
- âœ… Model management and downloading
- âœ… Navigation and UI responsiveness
- âœ… Settings persistence across app restarts

Notes:
- Integration `model_download` tests require network access and may need higher timeouts (e.g., `jest.setTimeout(30000)`) or mocked requests.
- Playwright/Electron E2E may error with `setImmediate is not defined`; add a safe polyfill in test setup: `global.setImmediate = (fn, ...args) => setTimeout(fn, 0, ...args);`.
- Renderer unit tests expose `window.__rendererTestHooks` to make UI updates deterministic in CI.

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgements & Inspirations

This project was made possible thanks to the amazing work of the open-source AI community and several commercial products that inspired its design.

### ğŸ§  Open-Source Projects
- **whisper.cpp** â€“ by ggml-org: the fully offline C/C++ Whisper implementation that powers this appâ€™s transcription engine.  
- **faster-whisper** â€“ by SYSTRAN: CTranslate2-based Whisper optimized for fast CPU/GPU inference.  
- **Const-me/Whisper** â€“ GPU-accelerated desktop Whisper engine that inspired local model integration.  
- **Rhasspy Wyoming Faster-Whisper** â€“ practical offline STT example used in Home Assistant voice systems.  
- **Handy (Tauri)** â€“ privacy-first local speech-to-text UX inspiration.  
- **Whisper-flow (library)** â€“ reference for real-time streaming transcription pipelines.  
- **AlexxIT/FasterWhisper Add-on** â€“ great packaging reference for self-hosted Whisper services. 

### ğŸ’¬ Commercial & UX Inspirations
- **Wispr Flow** â€“ for its smooth real-time dictation interface and workflow design.  
- **Typeless** â€“ for its minimal, distraction-free speech-to-text UX.  
- **MacWhisper / Whisper Desktop / WhisperNote** â€“ for early attempts at offline Whisper usability.  
- **Descript & Otter.ai** â€“ for industry-leading transcription and editing experiences that inspired the UX of this offline version. 



### âš™ï¸ Development Tools

This project was built using the following development tools and AI assistants:

- **Cursor Free/Pro (7-day trial)** â€“ Primary IDE with AI-powered development assistance
- **VS Code** â€“ Code editor for development and debugging
- **KiloCode** â€“ AI coding assistant for enhanced productivity
- **Klein** â€“ Development tool for code optimization
- **RooCode** â€“ AI-powered code generation and refactoring

> These tools enabled rapid development and professional-grade code quality as a solo developer. The collaborative use of multiple AI-augmented development environments demonstrates the power of modern development tooling.
---

> Built independently and completely offline with respect for all the creators above.  
> Special thanks to **Cursor Free/Pro**, **KiloCode**, **VS Code**, **Klein**, and **RooCode** for enabling professional-grade AI-augmented development.  
> Goal: Obtain **Cursor Ultra** or alternative professional development tools to continue innovation.  
> All trademarks belong to their respective owners. 

---

## ğŸ’ Sponsors & Support

### ğŸ¯ Our Goal: Professional Development Tools & Sponsorship

SONU was developed using a comprehensive suite of AI-augmented development tools, including **Cursor Free/Pro (7-day trial)**, **KiloCode**, **VS Code**, **Klein**, and **RooCode**. This collaborative approach enabled rapid, high-quality software development and demonstrates the power of modern AI-assisted development workflows.

To continue delivering professional-grade features and maintain the development momentum, **our primary goal is to obtain a Cursor Ultra subscription**. However, **we welcome any form of sponsorship or support**â€”whether it's Cursor Ultra, alternative development tools, direct contributions, or other forms of assistance. **Any help and donation is greatly appreciated and makes a meaningful difference**.

<div align="center">

### â˜• Support Development via Ko-fi

<a href="https://ko-fi.com/ai_dev_2024" target="_blank">
  <img src="https://img.shields.io/badge/â˜•%20Support%20on%20Ko--fi-FF5E5B?style=for-the-badge&logo=ko-fi&logoColor=white" alt="Support on Ko-fi" height="40" />
</a>

**[ğŸ‘‰ Donate Now](https://ko-fi.com/ai_dev_2024)** | Any contribution makes a meaningful difference! ğŸ™

</div>

### Why Professional Development Tools Matter

Professional development tools like Cursor Ultra (or alternative solutions) will be the engine that enables SONU's continued rapid development and professional code quality:

- ğŸš€ **Advanced AI Features**: Real-time code completion, generation, and refactoring
- âš¡ **10x Faster Development**: Accelerated development cycles with AI assistance
- ğŸ¯ **Superior Code Quality**: AI-powered code review and optimization
- ğŸ’¼ **Enterprise-Grade Tools**: Professional development environment
- ğŸ”„ **Continuous Innovation**: Enables rapid iteration and feature development

### Impact of Your Support

When you support SONU, you're directly contributing to:

- âœ… **Professional Development Tools** â€“ Enabling access to Cursor Ultra or alternative professional development tools for continued development
- âœ… **Faster Updates** â€“ More frequent releases and bug fixes
- âœ… **Better Features** â€“ Enhanced functionality and user experience
- âœ… **Long-term Sustainability** â€“ Ensuring SONU continues to evolve and improve
- âœ… **Community Growth** â€“ Supporting open-source innovation and accessibility

### How You Can Help

<div align="center">

| Action | Impact |
|:------:|:------:|
| [â˜• **Donate via Ko-fi**](https://ko-fi.com/ai_dev_2024) | Directly supports development tools and continued development |
| â­ **Star the repository** | Shows appreciation and helps others discover SONU |
| ğŸ› **Report issues** | Helps improve stability and features |
| ğŸ’¡ **Suggest features** | Guides development priorities |
| ğŸ”„ **Share the project** | Spreads awareness and grows the community |

</div>

### Thank You! ğŸ™

Your support, whether through donations, sponsorships, stars, feedback, or sharing, makes a real difference. We are grateful for any form of assistanceâ€”whether it's helping obtain Cursor Ultra, providing alternative development tools, or direct contributions. Together, we can maintain the professional development tools that make SONU possible and continue building an exceptional offline voice typing experience.

<div align="center">

[![Cursor](https://img.shields.io/badge/Built%20with-Cursor%20Free%2FPro-blue?style=for-the-badge&logo=cursor&logoColor=white)](https://cursor.sh) [![Goal](https://img.shields.io/badge/Goal-Cursor%20Ultra-purple?style=for-the-badge&logo=cursor&logoColor=white)](https://cursor.sh)

*Developed with Cursor Free/Pro (7-day trial) Â· Goal: Cursor Ultra for continued development*

</div>

---

## ğŸ“ Support

For issues, questions, or feature requests:

- **GitHub Issues**: [Create an issue](https://github.com/ai-dev-2024/sonu/issues)
- **GitHub Profile**: [@ai-dev-2024](https://github.com/ai-dev-2024)

---

## ğŸ—ºï¸ Roadmap

### Version 3.6 (Planned)

- [ ] Multi-language support
- [ ] Advanced audio processing
- [ ] Custom model fine-tuning
- [ ] Plugin system

### Future Considerations

- [ ] macOS and Linux support
- [ ] API for third-party integrations
- [ ] Enterprise deployment tools
- [ ] Mobile companion app

---

<div align="center">

**Made with â¤ï¸ by a solo developer using Cursor Free/Pro (7-day trial), KiloCode, VS Code, Klein, and RooCode**

*Built to demonstrate the power of AI-augmented development*

[Documentation](docs/README.md) â€¢ [Changelog](CHANGELOG.md) â€¢ [Contributing](CONTRIBUTING.md) â€¢ [License](LICENSE)

Â© 2025 SONU. All rights reserved.

</div>
<!-- Showcase consolidated in the main Screenshots section above -->
