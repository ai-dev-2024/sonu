# SONU - Offline Voice Typing Application

<div align="center">

![SONU Logo](assets/tray/mic-32.png)

**Professional-grade offline voice typing solution powered by Faster-Whisper AI**

[![Video Formats](https://img.shields.io/badge/video-MP4%20%7C%20H.265%20%7C%20VP9-orange)](#-showcase)
[![Screenshots](https://img.shields.io/badge/screenshots-17-blue)](#-showcase)
[![Version](https://img.shields.io/badge/version-3.5.4-blue.svg)](https://github.com/1111MK1111/sonu)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![Platform](https://img.shields.io/badge/platform-Windows-lightgrey.svg)](https://www.microsoft.com/windows)
[![Python](https://img.shields.io/badge/python-3.8%2B-blue.svg)](https://www.python.org/)
[![Node.js](https://img.shields.io/badge/node.js-16.0%2B-green.svg)](https://nodejs.org/)

*Transform your voice into text instantly, completely offline, with enterprise-grade accuracy*

</div>

<div align="center">

<!-- Banner GIF/PNG preview -->
![SONU Showcase Banner](assets/showcase/banner.png)

<br/>
<sub>Quickstart showcase generation: <code>npm run showcase</code> Â· Banner: <code>npm run banner</code></sub>

</div>

---

## ğŸ“¸ Showcase

<div align="center">

### Application Overview

<table>
  <tr>
    <td align="center"><strong>Home Dashboard</strong></td>
    <td align="center"><strong>Dictionary Workspace</strong></td>
    <td align="center"><strong>Snippets Library</strong></td>
  </tr>
  <tr>
    <td><img src="apps/desktop/assets/showcase/01-home.png" alt="Home Dashboard" width="100%"></td>
    <td><img src="apps/desktop/assets/showcase/02-dictionary.png" alt="Dictionary Workspace" width="100%"></td>
    <td><img src="apps/desktop/assets/showcase/03-snippets.png" alt="Snippets Library" width="100%"></td>
  </tr>
  <tr>
    <td align="center"><strong>Style Presets</strong></td>
    <td align="center"><strong>Notes Dashboard</strong></td>
    <td align="center"><strong>Settings - General</strong></td>
  </tr>
  <tr>
    <td><img src="apps/desktop/assets/showcase/04-style.png" alt="Style Presets" width="100%"></td>
    <td><img src="apps/desktop/assets/showcase/05-notes.png" alt="Notes Dashboard" width="100%"></td>
    <td><img src="apps/desktop/assets/showcase/06-settings-general.png" alt="Settings - General" width="100%"></td>
  </tr>
  <tr>
    <td align="center"><strong>Settings - System</strong></td>
    <td align="center"><strong>Settings - Model Selector</strong></td>
    <td align="center"><strong>Settings - Themes</strong></td>
  </tr>
  <tr>
    <td><img src="apps/desktop/assets/showcase/07-settings-system.png" alt="Settings - System" width="100%"></td>
    <td><img src="apps/desktop/assets/showcase/08-settings-model.png" alt="Settings - Model Selector" width="100%"></td>
    <td><img src="apps/desktop/assets/showcase/09-settings-themes.png" alt="Settings - Themes" width="100%"></td>
  </tr>
  <tr>
    <td colspan="3" align="center"><strong>Dark Theme</strong></td>
  </tr>
  <tr>
    <td colspan="3"><img src="apps/desktop/assets/showcase/10-home-dark.png" alt="Home in Dark Theme" width="100%"></td>
  </tr>
</table>

### Video Showcase

<table>
  <tr>
    <td colspan="3" align="center">
      <h3>ğŸ¬ Video Demonstrations</h3>
      <p>
        <a href="apps/desktop/assets/showcase/showcase.mp4">ğŸ“¹ MP4 Montage</a> Â·
        <a href="apps/desktop/assets/showcase/showcase_vp9.webm">ğŸ“¹ VP9 Montage</a> Â·
        <a href="apps/desktop/assets/showcase/showcase_h265.mp4">ğŸ“¹ HEVC Montage</a>
      </p>
      <p>
        <strong>Slideshows:</strong><br>
        <a href="apps/desktop/assets/showcase/showcase_slideshow_h265.mp4">HEVC Slideshow</a> Â·
        <a href="apps/desktop/assets/showcase/showcase_slideshow_vp9.webm">VP9 Slideshow</a> Â·
        <a href="apps/desktop/assets/showcase/showcase_slideshow_3s_h265.mp4">HEVC (Ken Burns)</a> Â·
        <a href="apps/desktop/assets/showcase/showcase_slideshow_3s_vp9.webm">VP9 (Ken Burns)</a>
      </p>
    </td>
  </tr>
</table>

<sub>âœ¨ Screenshots and videos are auto-generated via <code>npm run showcase</code> and saved to <code>apps/desktop/assets/showcase/</code></sub>

</div>
---

## ğŸš€ Overview

**SONU** is a cutting-edge desktop application that provides real-time voice-to-text transcription using OpenAI's Whisper model via the faster-whisper library, running entirely offline on your Windows machine. Built with Electron and Python using Cursor, VSCode, and AI-powered development tools, SONU offers a seamless, privacy-focused dictation experience that works across all your applications.

### Key Highlights

- âœ… **100% Offline** - No internet connection required, complete privacy
- âœ… **Real-time Transcription** - Live partial results during dictation
- âœ… **Dual Interaction Modes** - Press-and-hold or toggle on/off
- âœ… **System-wide Integration** - Works in any application
- âœ… **Professional UI** - Modern, glassmorphic design with light/dark themes
- âœ… **Enterprise Ready** - Commercial-grade architecture and documentation
- âœ… **Faster-Whisper Powered** - CPU-optimized transcription engine

---

## âœ¨ Features

### Core Functionality

- **Press-and-Hold Mode**: Hold a hotkey to dictate, release to finalize and output text
- **Toggle Mode**: Start/stop continuous dictation with a single keypress
- **Instant Hotkey Response**: Zero-latency hotkey triggering - dictation starts immediately
- **Live Preview**: See partial transcriptions in real-time during dictation
- **Instant System-wide Output**: Text appears instantly at cursor location in any application (like Wispr Flow)
  - Uses modern native addon for fastest typing performance
  - Automatic fallback to clipboard method for reliability
  - Works seamlessly across all Windows applications
- **Clipboard Integration**: Final transcriptions automatically copied to clipboard
- **History Management**: View, edit, and copy previous transcriptions (last 100 items)

### Model Management

- **Multiple Model Sizes**: Choose from tiny, base, small, medium, or large-v3 models
- **Auto-Download**: Automatic model download with progress tracking
- **Model Import**: Import locally downloaded models
- **Smart Recommendations**: System-based model recommendations
- **Cache Management**: Automatic detection of faster-whisper cache locations

### User Interface

- **Modern Design**: Glassmorphic UI inspired by Apple's design language
- **Theme Support**: Beautiful light and dim dark themes with smooth transitions
- **Responsive Layout**: Sidebar navigation with dedicated settings page
- **Live Statistics**: Track total transcriptions, words, and characters
- **Inline Editing**: Edit history items directly in the interface

### Advanced Features

- **Customizable Hotkeys**: Configure hold and toggle shortcuts to your preference
- **Instant Typing Technology**: Multi-tier typing system with automatic fallback
  - Primary: Native addon (`@xitanggg/node-insert-text`) for fastest performance
  - Fallback: Clipboard + Ctrl+V method (what Wispr Flow uses)
  - Final: Clipboard-only if automation unavailable
- **Audio Cues**: Audio feedback for dictation start/stop
- **Tray Integration**: System tray icon with comprehensive context menu
- **Window Controls**: Standard minimize, maximize, and close functionality
- **Version Management**: Built-in versioning system for development

---

## ğŸ“‹ Requirements

### System Requirements

- **OS**: Windows 10/11 (64-bit)
- **RAM**: Minimum 4GB (8GB recommended)
- **Storage**: 2GB free space (for models)
- **Audio**: Microphone input device

### Software Dependencies

- **Node.js**: v16.0.0 or higher
- **Python**: 3.8 or higher
- **Python Packages**:
  - `faster-whisper` (Whisper model implementation)
  - `pyaudio` (Audio capture)

---

## ğŸ› ï¸ Installation

### Prerequisites

1. **Install Node.js**
   ```bash
   # Download from https://nodejs.org/
   # Verify installation
   node --version
   npm --version
   ```

2. **Install Python**
   ```bash
   # Download from https://www.python.org/
   # Verify installation
   python --version
   pip --version
   ```

3. **Install Python Dependencies**
   ```bash
   pip install faster-whisper pyaudio
   ```

### Application Setup

1. **Clone the Repository**
   ```bash
   git clone https://github.com/1111MK1111/sonu.git
   cd sonu
   ```

2. **Navigate to Desktop App**
   ```bash
   cd apps/desktop
   ```

3. **Install Dependencies**
   ```bash
   npm install
   pip install -r requirements.txt
   ```

4. **Run the Application**
   ```bash
   npm start
   ```

### Building for Distribution

```bash
npm run build
```

This creates a Windows installer in the `dist` folder.

## ğŸ“¸ Automated Showcase Capture

Generate fresh screenshots of every major tab without manual clicking:

```bash
npm run showcase
```

The command launches SONU in a special showcase mode, walks through Home, Dictionary, Snippets, Style, Notes, and all Settings sub-pages, and saves PNGs to `assets/showcase/`. To turn the stills into a short MP4 for GitHub or the redbook, run (requires `ffmpeg`):

```bash
ffmpeg -y -framerate 1 -pattern_type glob -i "assets/showcase/*.png" -c:v libx264 -pix_fmt yuv420p assets/showcase/showcase.mp4
```

### Alternative: Playwright Automation

If you prefer Playwright-driven automation (video + screenshots), use:

```bash
npm run auto-screenshots
```

This runs `auto_screenshot.js`, capturing screenshots to `screenshots/` and a walkthrough video to `recordings/`. See `AUTOMATION_README.md` for details.

### Showcase Videos

- HEVC (H.265) slideshow: `assets/showcase/showcase_slideshow_h265.mp4`
- VP9 (WebM) slideshow: `assets/showcase/showcase_slideshow_vp9.webm`
- Original MP4 montage: `assets/showcase/showcase.mp4`
- Social-ready HEVC: `assets/showcase/showcase_h265.mp4`
- Social-ready VP9: `assets/showcase/showcase_vp9.webm`

--- 

## ğŸ¯ Usage

### First Launch

1. Launch SONU from the command line or desktop shortcut
2. The application will start minimized to the system tray
3. Right-click the tray icon to access the main window

### Basic Dictation

#### Press-and-Hold Mode

1. **Configure Hotkey**: Go to Settings â†’ Keyboard Shortcuts â†’ Hold Key
2. **Default**: `Ctrl+Win+Space` (customizable)
3. **Usage**: 
   - Hold the configured hotkey combination
   - Speak your text
   - Release to finalize and output

#### Toggle Mode

1. **Configure Hotkey**: Go to Settings â†’ Keyboard Shortcuts â†’ Toggle Key
2. **Default**: `Ctrl+Shift+Space` (customizable)
3. **Usage**:
   - Press once to start dictation
   - Speak your text (see live partial transcriptions in real-time)
   - Press again to stop and output text instantly
4. **Features**:
   - **Instant Output**: Text appears immediately when toggled off using the last partial transcription
   - **Live Previews**: Real-time partial transcriptions during recording (same as hold mode)
   - **Reliable**: Stable operation even with rapid toggle sequences

### Model Management

1. **Select Model**: Go to Settings â†’ Model Selector
2. **Download Model**: Click "Download and Apply" for your preferred model
3. **Import Model**: Use "Import Model File" to use a locally downloaded model
4. **Auto-Recommendation**: System will recommend the best model based on your hardware

### Advanced Usage

- **View History**: Access previous transcriptions from the Home page
- **Edit Transcripts**: Click any history item to edit before copying
- **Change Themes**: Toggle between light and dark themes via the header switch
- **Customize Settings**: Access comprehensive settings via the sidebar
- **Dictionary Management**: Add custom words to improve transcription accuracy
- **Waveform Animation**: Control the visual waveform indicator during dictation
  - Go to Settings â†’ Vibe Coding â†’ "Show Live Waveform Animation"
  - When **ON**: The floating widget with animated waveform bars appears during dictation
  - When **OFF**: Dictation works normally but the widget is completely hidden
  - The setting applies immediately - toggle it on/off while dictating to see the change

---

## âš™ï¸ Configuration

### Hotkey Configuration

Hotkeys are configured in the Settings UI (no config.json needed).

### Settings Configuration

Settings are stored in `apps/desktop/data/settings.json`:

```json
{
  "theme": "dark",
  "selected_model": "base",
  "dictation_hotkey": "Ctrl+Space",
  "sound_feedback": true,
  "waveform_animation": true,
  "model_download_path": ""
}
```

### Dictionary Management

Add custom words in the Dictionary tab of the app. Words are stored in `apps/desktop/data/dictionary.json`.

---

## ğŸ—ï¸ Architecture

### Technology Stack

- **Frontend**: Electron (Chromium + Node.js)
- **Backend**: Python 3.x
- **AI Model**: Faster-Whisper (OpenAI Whisper implementation)
- **UI Framework**: Vanilla HTML/CSS/JavaScript
- **System Integration**: robotjs (system-wide typing)

### Project Structure

```
sonu/
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ desktop/          # Desktop app (v3.x) - ACTIVE
â”‚   â”‚   â”œâ”€â”€ main.js       # Electron main process
â”‚   â”‚   â”œâ”€â”€ index.html    # Main UI
â”‚   â”‚   â”œâ”€â”€ renderer.js   # Renderer process
â”‚   â”‚   â”œâ”€â”€ package.json  # Desktop dependencies
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ mobile/           # Mobile app (v4+) - Future
â”œâ”€â”€ versions/             # Historical versions
â”‚   â”œâ”€â”€ v3.legacy/        # Archived root files
â”‚   â””â”€â”€ ...
â”œâ”€â”€ assets/               # Application assets
â”œâ”€â”€ docs/                 # Documentation
â”œâ”€â”€ scripts/              # Utility scripts
â”œâ”€â”€ tests/                # Test configurations
â””â”€â”€ [config files]        # Project-wide configs
```

### Key Components

1. **Main Process** (`main.js`): Window management, hotkey registration, IPC handling, model management
2. **Renderer Process** (`renderer.js`): UI state management, user interactions
3. **Whisper Service** (`whisper_service.py`): Audio capture and transcription using faster-whisper
4. **Preload Script** (`preload.js`): Secure IPC communication bridge
5. **Model Manager** (`model_manager.py`): Model download and cache management

### Faster-Whisper Integration

SONU uses **faster-whisper** (not whisper.cpp) for transcription:

- **Model Names**: Uses faster-whisper standard names (tiny, base, small, medium, large-v3)
- **Cache Location**: 
  - Windows: `%LOCALAPPDATA%\.cache\huggingface\hub\models--openai--whisper-{model}\`
  - Linux/Mac: `~/.cache/huggingface/hub/models--openai--whisper-{model}/`
- **Download**: Automatically downloads from Hugging Face Systran repositories
- **CPU Optimized**: Uses CTranslate2 for efficient CPU-based transcription

---

## ğŸ”’ Privacy & Security

- **100% Offline**: All processing happens locally on your machine
- **No Data Transmission**: Audio never leaves your device
- **No Telemetry**: Zero tracking or analytics
- **Open Source**: Full source code transparency
- **Local Storage**: All data stored locally in JSON files
- **No Cloud Sync**: All data remains on your device

---

## ğŸ› Troubleshooting

### Common Issues

**Issue**: Hotkeys not working
- **Solution**: Ensure no other application is using the same hotkey combination
- **Solution**: Check Windows permissions for global hotkey registration

**Issue**: Audio not being captured
- **Solution**: Verify microphone permissions in Windows Settings
- **Solution**: Check if microphone is set as default input device

**Issue**: Transcription not appearing
- **Solution**: Ensure Python dependencies are installed correctly
- **Solution**: Check console for error messages
- **Solution**: Verify faster-whisper is installed: `pip install faster-whisper`

**Issue**: System-wide typing not working
- **Solution**: Verify `robotjs` is installed: `npm install robotjs`
- **Solution**: Use clipboard fallback (`Ctrl+V`) if robotjs unavailable

**Issue**: Model download fails
- **Solution**: Check internet connection (required only for initial download)
- **Solution**: Verify faster-whisper is installed correctly
- **Solution**: Check disk space availability

### Performance Optimization

- **First Run**: Initial model loading may take 30-60 seconds
- **Memory Usage**: Whisper model requires ~2GB RAM (varies by model size)
- **CPU Usage**: Transcription is CPU-intensive; expect 20-40% usage
- **Model Selection**: Use smaller models (tiny, base) for faster transcription

---

## ğŸ“ Development

### Version History

See [CHANGELOG.md](CHANGELOG.md) for detailed version history.

### Contributing

We welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

1. Fork the repository
2. Create a feature branch from `main`
3. Make your changes
4. Test thoroughly
5. Submit a pull request

### Building from Source

```bash
# Navigate to desktop app
cd apps/desktop

# Install dependencies
npm install
pip install -r requirements.txt

# Run in development mode
npm start

# Build for production
npm run build
```

### Running Tests

#### Automated Testing (Recommended)

Run all tests, generate showcases, and upload to GitHub automatically:

```bash
cd apps/desktop
npm run test:auto
```

This command:
- âœ… Runs unit, integration, and E2E tests
- âœ… Tests all features: Dictionary, Snippets, Notes, Theme, Experimental toggles
- âœ… Generates showcase screenshots
- âœ… Uploads to GitHub automatically

#### Manual Testing

Run tests from the dedicated `tests` workspace:

```bash
cd apps/desktop/tests
npm install

# Unit / Integration / E2E
npm run test:unit
npm run test:integration
npm run test:e2e

# Complete functionality tests (all features)
npm run test:e2e:complete

# Real-time comprehensive tests (clicks all buttons, tests downloads, toggles, copy functions)
npm run test:realtime
```

Alternatively, from the project root using Jest directly:

```bash
npx jest tests/unit --runInBand
npx jest tests/integration --runInBand
npx jest tests/e2e --runInBand
```

#### Test Coverage

The comprehensive test suite covers:
- âœ… Dictionary CRUD operations (add, delete words)
- âœ… Snippets CRUD operations
- âœ… Notes CRUD operations
- âœ… Theme switching and persistence
- âœ… All experimental feature toggles (continuous dictation, low-latency, noise reduction)
- âœ… General settings toggles (sound feedback, waveform animation)
- âœ… Model management and downloading
- âœ… Navigation and UI responsiveness
- âœ… Settings persistence across app restarts

Notes:
- Integration `model_download` tests require network access and may need higher timeouts (e.g., `jest.setTimeout(30000)`) or mocked requests.
- Playwright/Electron E2E may error with `setImmediate is not defined`; add a safe polyfill in test setup: `global.setImmediate = (fn, ...args) => setTimeout(fn, 0, ...args);`.
- Renderer unit tests expose `window.__rendererTestHooks` to make UI updates deterministic in CI.

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgements & Inspirations

This project was made possible thanks to the amazing work of the open-source AI community and several commercial products that inspired its design.

### ğŸ§  Open-Source Projects
- **whisper.cpp** â€“ by ggml-org: the fully offline C/C++ Whisper implementation that powers this appâ€™s transcription engine.  
- **faster-whisper** â€“ by SYSTRAN: CTranslate2-based Whisper optimized for fast CPU/GPU inference.  
- **Const-me/Whisper** â€“ GPU-accelerated desktop Whisper engine that inspired local model integration.  
- **Rhasspy Wyoming Faster-Whisper** â€“ practical offline STT example used in Home Assistant voice systems.  
- **Handy (Tauri)** â€“ privacy-first local speech-to-text UX inspiration.  
- **Whisper-flow (library)** â€“ reference for real-time streaming transcription pipelines.  
- **AlexxIT/FasterWhisper Add-on** â€“ great packaging reference for self-hosted Whisper services. 

### ğŸ’¬ Commercial & UX Inspirations
- **Wispr Flow** â€“ for its smooth real-time dictation interface and workflow design.  
- **Typeless** â€“ for its minimal, distraction-free speech-to-text UX.  
- **MacWhisper / Whisper Desktop / WhisperNote** â€“ for early attempts at offline Whisper usability.  
- **Descript & Otter.ai** â€“ for industry-leading transcription and editing experiences that inspired the UX of this offline version. 



### âš™ï¸ Development Tools

This project was built using the following development tools and AI assistants:

- **Cursor** â€“ Primary IDE with AI-powered development assistance
- **VSCode** â€“ Code editor for development and debugging
- **KiloCode** â€“ AI coding assistant for enhanced productivity
- **Klein** â€“ Development tool for code optimization
- **RooCode** â€“ AI-powered code generation and refactoring

> These tools enabled rapid development and professional-grade code quality as a solo developer.
---

> Built independently and completely offline with respect for all the creators above.  
> Special thanks to **Cursor Ultra** for enabling professional-grade AI-augmented development.  
> All trademarks belong to their respective owners. 

---

## ğŸ’ Sponsors & Support

### Cursor Ultra Sponsorship

This project is made possible thanks to **Cursor Ultra** subscription, which provides:

- ğŸš€ **Advanced AI Features**: Enhanced code completion and generation
- âš¡ **Faster Development**: Accelerated development cycles
- ğŸ¯ **Better Code Quality**: AI-powered code review and optimization
- ğŸ’¼ **Professional Tools**: Enterprise-grade development environment

**Want to support continued development?**

If you find SONU useful and want to help maintain and improve it, consider:

- â­ **Star the repository** â€“ Show your support
- ğŸ› **Report issues** â€“ Help improve the app
- ğŸ’¡ **Suggest features** â€“ Share your ideas
- ğŸ’° **Sponsor development** â€“ Help cover Cursor Ultra costs

Your support enables continued development and feature additions. Thank you! ğŸ™

<div align="center">

[![Sponsor](https://img.shields.io/badge/Sponsor-Cursor%20Ultra-purple?style=for-the-badge)](https://cursor.sh)

*Supporting professional AI-augmented development*

</div>

---

## ğŸ“ Support

For issues, questions, or feature requests:

- **GitHub Issues**: [Create an issue](https://github.com/1111MK1111/sonu/issues)
- **GitHub Profile**: [@1111MK1111](https://github.com/1111MK1111)

---

## ğŸ—ºï¸ Roadmap

### Version 3.6 (Planned)

- [ ] Multi-language support
- [ ] Advanced audio processing
- [ ] Custom model fine-tuning
- [ ] Plugin system

### Future Considerations

- [ ] macOS and Linux support
- [ ] API for third-party integrations
- [ ] Enterprise deployment tools
- [ ] Mobile companion app

---

<div align="center">

**Made with â¤ï¸ by a solo developer using Cursor, VSCode, and AI-powered development tools**

*Built to demonstrate the power of AI-augmented development*

[Documentation](docs/README.md) â€¢ [Changelog](CHANGELOG.md) â€¢ [Contributing](CONTRIBUTING.md) â€¢ [License](LICENSE)

Â© 2025 SONU. All rights reserved.

</div>
<!-- Showcase consolidated in the main Screenshots section above -->
